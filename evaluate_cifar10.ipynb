{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose from '64', '256', '1024'\n",
    "dense_units = '256'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oh(ys,n):\n",
    "    return np.stack([\n",
    "        np.arange(n) == y for y in ys\n",
    "        ]) * 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "\n",
    "y_train = np.concatenate(y_train)\n",
    "y_test = np.concatenate(y_test)\n",
    "\n",
    "y_train_oh = oh(y_train,NUM_CLASSES)\n",
    "y_test_oh = oh(y_test,NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_indices(a, classes):\n",
    "    if not classes:\n",
    "        return np.repeat(True, a.shape[0])\n",
    "\n",
    "    return np.all([a != cl for cl in classes], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(classes):\n",
    "    ind = filter_indices(y_train, classes)\n",
    "\n",
    "    x_train_nocl = x_train[ind]\n",
    "    y_train_nocl = y_train[ind]\n",
    "    y_train_oh_nocl = np.delete(y_train_oh[ind],classes,1)\n",
    "\n",
    "    ind_test = filter_indices(y_test, classes)\n",
    "\n",
    "    x_test_nocl = x_test[ind_test]\n",
    "    y_test_nocl = y_test[ind_test]\n",
    "    y_test_oh_nocl = np.delete(y_test_oh[ind_test],classes,1)\n",
    "\n",
    "    return (x_train_nocl, y_train_nocl, y_train_oh_nocl, x_test_nocl, y_test_nocl, y_test_oh_nocl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_split(data, ratio=.3):\n",
    "    N = data.shape[0]\n",
    "    split = int(N * ratio)\n",
    "    return data[split:],data[:split] \n",
    "\n",
    "def flatten(data):\n",
    "    return data.reshape((data.shape[0]*data.shape[1],data.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(p1, p2, k=500, l=500, ratio=.3):\n",
    "    \n",
    "    p1_train, p1_test = make_split(p1, ratio=ratio)\n",
    "    p1_train = flatten(p1_train[:,np.random.permutation(p1_train.shape[1])[:k]])\n",
    "    p1_test = flatten(p1_test[:,np.random.permutation(p1_test.shape[1])[:l]])\n",
    "\n",
    "    p2_train, p2_test = make_split(p2, ratio=ratio)\n",
    "    p2_train = flatten(p2_train[:,np.random.permutation(p2_train.shape[1])[:k]])\n",
    "    p2_test = flatten(p2_test[:,np.random.permutation(p2_test.shape[1])[:l]])\n",
    "\n",
    "    train_data = np.concatenate([p1_train, p2_train])\n",
    "    test_data = np.concatenate([p1_test, p2_test])\n",
    "    \n",
    "    train_labels = np.concatenate(\n",
    "        [np.ones(p1_train.shape[0]), np.zeros(p2_train.shape[0])]\n",
    "    )\n",
    "    test_labels = np.concatenate(\n",
    "        [np.ones(p1_test.shape[0]), np.zeros(p2_test.shape[0])]\n",
    "    )\n",
    "    \n",
    "    train_perm = np.random.permutation(train_data.shape[0])\n",
    "    train_data = train_data[train_perm]\n",
    "    train_labels = train_labels[train_perm]\n",
    "    \n",
    "    test_perm = np.random.permutation(test_data.shape[0])\n",
    "    test_data = test_data[test_perm]\n",
    "    test_labels = test_labels[test_perm]\n",
    "    \n",
    "    return (train_data, train_labels, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(data, sm=False, silent=False):\n",
    "\n",
    "    (train_data, train_labels, test_data, test_labels) = data\n",
    "    if sm:\n",
    "        train_data = softmax(train_data, axis=-1)\n",
    "        test_data = softmax(test_data, axis=-1)\n",
    "\n",
    "    if not silent:\n",
    "        print('training svm on {} samples, testing on {} samples'.format(train_data.shape[0], test_data.shape[0]))\n",
    "\n",
    "    clfs = {}\n",
    "    clfs['K-NN'] = KNeighborsClassifier(5)\n",
    "    clfs['Random Forest'] = RandomForestClassifier(max_depth=5, n_estimators=10)\n",
    "    clfs['AdaBoost'] = AdaBoostClassifier()\n",
    "\n",
    "    r = []\n",
    "    for clf_name in clfs:\n",
    "        clf = clfs[clf_name]\n",
    "        clf.fit(train_data, train_labels)\n",
    "\n",
    "        train_acc = np.sum(clf.predict(train_data) == train_labels)/train_labels.shape[0]\n",
    "        test_acc = np.sum(clf.predict(test_data) == test_labels)/test_labels.shape[0]\n",
    "\n",
    "        if not silent:\n",
    "            print('{} train accuracy'.format(train_acc))\n",
    "            print('{} test accuracy'.format(test_acc))\n",
    "\n",
    "        r.append((train_acc, test_acc, clf_name))\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_pred_path(name, i, dir):\n",
    "#     return os.path.join(dir, 'test_' + name + '_' + str(i) + '.npy')\n",
    "\n",
    "# preds = np.stack([\n",
    "#     np.load(test_pred_path('cifar10_cnn'+dense_units+'_full_transfer', i, 'predictions_cifar10')) for i in range(100)\n",
    "# ])\n",
    "\n",
    "# def test_pred_path_total(name, dir):\n",
    "#     return os.path.join(dir, 'test_' + name + '.npy')\n",
    "\n",
    "# np.save(test_pred_path_total('cifar10_cnn'+dense_units+'_full_transfer', 'predictions_cifar10'), preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = {}\n",
    "\n",
    "P['p_full'] = np.load(os.path.join('predictions_cifar10','test_cifar10_cnn'+dense_units+'_full.npy'))\n",
    "P['p_nocl0'] = np.load(os.path.join('predictions_cifar10','test_cifar10_cnn'+dense_units+'_del0.npy'))\n",
    "\n",
    "P['p_transfer'] = np.load(os.path.join('predictions_cifar10','test_cifar10_cnn'+dense_units+'_full_transfer.npy'))\n",
    "P['p_transfer2'] = P['p_transfer']\n",
    "\n",
    "def filter_helper(key):\n",
    "    if key=='p_full':\n",
    "        return []\n",
    "    return [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P['p_naive'] = P['p_full'][:,:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import filtration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P['p_lin_norm_mean'] = np.stack([\n",
    "    np.transpose(np.matmul(\n",
    "        filtration.filtration_matrix(\n",
    "            P['p_full'][i], y_test, NUM_CLASSES, [0], mode='normalization'\n",
    "        ), np.transpose(P['p_full'][i])))\n",
    "    for i in range(P['p_full'].shape[0])])\n",
    "\n",
    "def sample(x, y, s):\n",
    "    return np.concatenate([\n",
    "        x[y == i][:s]\n",
    "        for i in range(NUM_CLASSES)])\n",
    "\n",
    "P['p_lin_norm_mean10'] = np.stack([\n",
    "    np.transpose(np.matmul(\n",
    "        filtration.filtration_matrix(\n",
    "            sample(P['p_full'][i], y_test, 10), sample(y_test, y_test, 10), NUM_CLASSES, [0], mode='normalization'\n",
    "        ), np.transpose(P['p_full'][i])))\n",
    "    for i in range(P['p_full'].shape[0])])\n",
    "\n",
    "P['p_lin_norm_mean100'] = np.stack([\n",
    "    np.transpose(np.matmul(\n",
    "        filtration.filtration_matrix(\n",
    "            sample(P['p_full'][i], y_test, 100), sample(y_test, y_test, 100), NUM_CLASSES, [0], mode='normalization'\n",
    "        ), np.transpose(P['p_full'][i])))\n",
    "    for i in range(P['p_full'].shape[0])])\n",
    "\n",
    "P['p_lin_random'] = np.stack([\n",
    "    np.transpose(np.matmul(\n",
    "        filtration.filtration_matrix(\n",
    "            P['p_full'][i], y_test, NUM_CLASSES, [0], mode='randomization'\n",
    "        ), np.transpose(P['p_full'][i])))\n",
    "    for i in range(P['p_full'].shape[0])])\n",
    "\n",
    "P['p_lin_zero'] = np.stack([\n",
    "    np.transpose(np.matmul(\n",
    "        filtration.filtration_matrix(\n",
    "            P['p_full'][i], y_test, NUM_CLASSES, [0], mode='zeroing'\n",
    "        ), np.transpose(P['p_full'][i])))\n",
    "    for i in range(P['p_full'].shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Names = {}\n",
    "Names['p_nocl0'] = 'Retraining'\n",
    "Names['p_nocl0_second'] = 'Retraining2'\n",
    "Names['p_lin_norm_mean'] = 'Normalization'\n",
    "Names['p_lin_norm_mean10'] = 'Normalization (s=10)'\n",
    "Names['p_lin_norm_mean100'] = 'Normalization (s=100)'\n",
    "Names['p_lin_random'] = 'Randomization'\n",
    "Names['p_lin_zero'] = 'Zeroing'\n",
    "Names['p_naive'] = 'Naive'\n",
    "Names['p_full'] = 'Before unlearning'\n",
    "Names['p_transfer'] = 'Transfer'\n",
    "Names['p_transfer2'] = 'Transfer2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_label_map(filter):\n",
    "    return [i for i in range(NUM_CLASSES) if i not in filter]\n",
    "\n",
    "def evaluate_predictions(predictions, filter=[]):\n",
    "    l_map = make_label_map(filter)\n",
    "    f_i = filter_indices(y_test,filter)\n",
    "    \n",
    "    accs = []\n",
    "    losses = []\n",
    "    \n",
    "    labels_oh = filter_data(filter)[5] ## 2\n",
    "    \n",
    "    for p in predictions[:,f_i]:\n",
    "        a = np.argmax(p,axis=1)\n",
    "        l = np.array([l_map[i] for i in a])\n",
    "        accs.append((l == y_test[f_i]).mean())\n",
    "        \n",
    "        s = softmax(p,axis=1)\n",
    "        s = s * labels_oh\n",
    "        s = -np.log(np.sum(s,axis=1)).mean()\n",
    "        losses.append(s)\n",
    "        \n",
    "    accs = np.array(accs) * 100\n",
    "    losses = np.array(losses)\n",
    "    return accs.mean(), losses.mean(), accs.std(), losses.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in P:\n",
    "    a, l, a_std, l_std = evaluate_predictions(P[p], filter_helper(p))\n",
    "    print('{:0.1f} +- {:0.2f} \\t {:0.2f} +- {:0.2f} \\t {}'.format(a, a_std, l, l_std, Names[p]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [\n",
    "    ('p_naive', 'p_nocl0'),\n",
    "    ('p_lin_norm_mean', 'p_nocl0'),\n",
    "    ('p_transfer', 'p_nocl0'),\n",
    "    ('p_transfer2', 'p_nocl0'),\n",
    "#     ('p_lin_norm_mean10', 'p_nocl0'),\n",
    "#     ('p_lin_norm_mean100', 'p_nocl0'),\n",
    "#     ('p_lin_random', 'p_nocl0'),\n",
    "#     ('p_lin_zero', 'p_nocl0'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1\n",
    "\n",
    "A = {}\n",
    "for (p1,_) in C:\n",
    "    A[p1] = [np.zeros(N),np.zeros(N),np.zeros(N)]\n",
    "\n",
    "for c in tqdm(range(N)):\n",
    "    f = y_test == c\n",
    "    for (p1,p2) in C:\n",
    "        data = prepare_data(P[p1][:,f], P[p2][:,f], k=150, l=150)\n",
    "        r = compare(data, sm=False, silent=True)\n",
    "        i = 0\n",
    "        for (_,test_acc,_) in r:\n",
    "            A[p1][i][c] += (test_acc - .5) * 2\n",
    "            i += 1\n",
    "        \n",
    "for (p1, _) in C:\n",
    "    for i in range(3):\n",
    "        print('{:0.3f} \\t'.format(A[p1][i].mean()), end='')\n",
    "    print('{}'.format(Names[p1]), end='')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1\n",
    "\n",
    "A = {}\n",
    "for (p1,_) in C:\n",
    "    A[p1] = [np.zeros(NUM_CLASSES-N),np.zeros(NUM_CLASSES-N),np.zeros(NUM_CLASSES-N)]\n",
    "\n",
    "for c in tqdm(range(N,NUM_CLASSES)):\n",
    "    f = y_test == c\n",
    "    for (p1,p2) in C:\n",
    "        data = prepare_data(P[p1][:,f], P[p2][:,f], k=150, l=150)\n",
    "        r = compare(data, sm=False, silent=True)\n",
    "        i = 0\n",
    "        for (_,test_acc,_) in r:\n",
    "            A[p1][i][c-N] += (test_acc - .5) * 2\n",
    "            i += 1\n",
    "        \n",
    "for (p1, _) in C:\n",
    "    for i in range(3):\n",
    "        print('{:0.3f} \\t'.format(A[p1][i].mean()), end='')\n",
    "    print('{}'.format(Names[p1]), end='')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_distributions(x):\n",
    "    num_classes = x.shape[2]\n",
    "    x = np.argmax(x,axis=-1)\n",
    "    x = np.array([np.sum(x[m] == i)/x.shape[1] for m in range(x.shape[0]) for i in range(num_classes)]).reshape(x.shape[0],num_classes)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "# import tikzplotlib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [\n",
    "    'p_nocl0',\n",
    "    'p_lin_norm_mean',\n",
    "    'p_transfer',\n",
    "    'p_naive'\n",
    "]\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "legends = []\n",
    "\n",
    "for (p,i,c) in zip(X,range(len(X)), ['#D81B60','#3892E0','#FFC107','tab:green']):\n",
    "    offset = .07\n",
    "    x = make_distributions(P[p][:,y_test==0])\n",
    "    plt.errorbar(np.array(range(1,10))+offset*i, x.mean(axis=0), yerr=x.std(axis=0), fmt='none', capsize=5, ecolor=c)\n",
    "    patch = mpatches.Patch(color=c, label=Names[p])\n",
    "    legends.append(patch)\n",
    "\n",
    "plt.legend(handles=legends)\n",
    "plt.ylabel('Probability')\n",
    "\n",
    "plt.xticks(list(range(1,10)),\n",
    "          [\n",
    "              'autom.',\n",
    "              'bird',\n",
    "              'cat',\n",
    "              'deer',\n",
    "              'dog',\n",
    "              'frog',\n",
    "              'horse',\n",
    "              'ship',\n",
    "              'truck',\n",
    "          ],rotation=45)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
